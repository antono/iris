---------------------------------------------------------------------------
Iris 0.3.0
---------------------------------------------------------------------------

* Valgrind tasks-1 and process-1 a  bit

* I think rename was_canceled back to is_canceled ...

* iris_receiver_destroy() shouldn't take those parameters. Message processing
  should be quick; maybe put a note to that effect in the docs. A scheduler
  can provide an 'iterate' function which would iterate the gmain context, or
  nothing in other cases.

* Grep FIXME

* Finish docs - README and gtk-doc tutorials :(

* Doc hosting; chergerts is out of date ..

* Stress the point that all of libiris is MT-safe and all of libiris-gtk is not
  We need a constistent story on thread safety ..

* I think shared library build with make is broken .

* Fix progress-chains disappearing dialog bug ... :(

* Prevent arbiters from being connected to receivers that have already processed
  messages.

* Same for ports.

* Fix immutability in general (see chergert mail)
  -> in task & process, add to both function and message handler, for easier
  debugging (better if we catch it right when the function was called, but the
  vagaries of message passing means it won't always work)

Should anything be allowed to happen after execution begins? Currently on tasks
you can add callbacks/errbacks and dependencies, add watches, and it even seems
you can execute tasks again once they are finished :/ This is a reciple for
nasty race conditions down the line. It should be handled but not allowed, using
an assertion or two. For processes you should be allowed to do stuff until BOTH
iris_process_no_more_work() or iris_process_run() are called, for tasks just
until iris_tasks_run() is called. Need to update:
  -> the docs
  -> put in the tests and the assertions

What about chaining together processes that are being cancelled, is this possible?
The tests could be cancelled before they run; add a testcase for this.

* What to do about gtk2/gtk3?
  -> seems like the approach is to require gtk3; other projects eg. clutter-gtk I guess you have
     to use an appropriately old version to run with gtk2, or peas-gtk which allows an "experimental"
     gtk2 version only.

* Check all examples and tests!

* Bump version to 0.3, and maybe give Iris a blog post :)

---------------------------------------------------------------------------
Known bugs
---------------------------------------------------------------------------

* tests/task-1 leaks mock schedulers like it's going out of fashion. Better
  maybe to provide iris_set_default_*_scheduler(NULL) which returns to the
  real default. Or not use set_default, which might be better still !
  It's a shame we don't have floating refs on schedulers but it doesn't
  really make sense .. just have to use fixtures.

* In IrisProgressDialog, the dialog is sometimes blank. I found it in
  examples/progress-chains-gtk. This is very hard to reproduce, but here's
  what I have found:
    - group->visible flag is set to correct values
    - group->toplevel has a parent  
  so far I have tried changing gtk_widget_show (group->toplevel) to
  gtk_widget_show (priv->box) in show_group() in gtk-iris-progress-dialog.c ...
  I doubt that will fix it.

* The scheduling is very dumb.

* Tests /process/cancel chain - head/tail run very slowly at the moment. This
  is due to dumb process scheduling: the tail process runs
  time_waster_callback() which of course is slow. Process work functions only
  yield every 1s so it takes a couple of seconds for the cancel to propagate
  from the head process to the tail on each run. The solution is to improve
  process scheduling (see above, it's dumb) so that cancels are recognised
  much faster.

---------------------------------------------------------------------------
Things for next version
---------------------------------------------------------------------------

* I think tasks & processes should gain a state system. The flags are really
  doing this anyway, it would make atomic changes a lot easier and remove
  some flags, and make the internals easier to understand. I see tasks having
  4 phases: creation, work execution, callbacks, finished. Processes have the
  preparation stage where work is enqueued, but this must be separate because
  it can be going on while the process is actually executing.

---------------------------------------------------------------------------
Missing or Incompleteness
---------------------------------------------------------------------------

Why do the recursion tests take so long?

info-bar: size-group for titles? This would make examples/progress-groups prettier

General test improvements needed:
  * Tests should always use a fresh scheduler, no?
  * How much of tests/progress-monitor-gtk-1 could use wait-func instead of count-sheep-func???
  * Add libtestutils and factor out some of the tests' shared code
  * Disallow g_sleep to allow messages to be delivered; we should use mocks
    where possible and spy on the message channel for what we want when not .. even
    wait_messages in process-1.c is way better than g_usleep()

waf should build the gtk-docs

What about errors in processes? There are two possibilites -
  1. a fatal error prevents further work and can be handled as an iristask error
  2. a per-item error means one work item can't be processed. What would you do
     about this ? an example is eg. file not found in a list of files to process.
     Can you store all of the errors and pass them back as GErrors? Or you could
     use some custom mechanism ...

You should add progress monitor support for tasks and processes that have thrown
fatal errors as well ...

Atomic access to variables in iristask is poor at best.

The IrisProgressMonitor examples could perhaps be described using a couple of
screenshots.
To do this in gtk-doc you do:
  <inlinegraphic fileref="gnome-foo.png" format="PNG" />
then add the file in doc/makefile.am:
  HTML_IMAGES= \
          $(srcdir)/images/gnome-foo.png

When I added the 'closed' API I broke IrisLFQueue and IrisWSQueue :( While
there, they each have their own unit tests which duplicate some code, we
could make a shared test.

We are not currently destroying threads ever. After they are created they
stay created until the end of the process. We need to find a way to
periodically walk the free-list to shutdown old threads.

GIO has some async primitives of its own. Other than in
iris_task_run_with_async_result() we don't really take advantage of them. Could
we replace bits of Iris with the glib code?

Also, what's this? http://repnop.org/ck/  - a possible source of existing
concurrency primitives to save having to manage our own in Iris. However
some of the stuff is duplicated in GLib.


IrisScheduler

	iris_scheduler_foreach () is a big bunch of code that should be a lot
	neater.

IrisProcess

	Currently IrisProcess is really, really dumb and inefficient (especially when
	idle). The current system is to see if there is any work using try_pop() and if
	not, re-enqueue the process back into the scheduler to check again immediately.
	We also yield to the scheduler in this way occasionally based on time to allow
	the scheduler to decide if it wants to add more threads, etc. This is good for
	now because the scheduler does not get as blocked up but is very wasteful
	when processes are waiting around.

	Things to consider:
	  - we could create an IrisProcessScheduler, which could peek into queues
	    and not execute a work function for processes with no work, saving on
	    having a thread blocking on the queue.  This falls down on the fact
	    that only Windows can block on multiple conds at once in one thread, I
	    think. Unless we create a special queue where they all signal one cond
	    to wake up the scheduler's main thread, this might be a no go

	  - is one thread per process a reasonable assumption? if the process runs
	    IO-bound items, it really wants as many threads as are available within
	    reason, and certainly sharing threads would not make sense. For CPU
	    bound processes there is no reason to run more threads than there are
	    cores, but a dedicated thread is still good perhaps to improve
	    multitasking. The only time a process would not need its own dedicated
	    thread is if it spends most of its time waiting for work, but is that a
	    common use-case? The whole point of process is that it's stuff that
	    takes a long time to process, if we have more occasional single-shot
	    work then IrisTask, maybe wrapped by some IrisService, is a better fit.
	
	So the possible models:
	  1. no dedicated threads, work items pulled from the process and scheduled
	     by IrisProcessScheduler => silly for IO-bound processes
	  2. one dedicated thread which passes work off into others when need be
	     (exactly how IrisThread works in fact - can we not take advantage of
	     that?) => good for CPU and IO-bound processes
	  3. multiple dedicated threads all running through the work queue
	     => good for IO bound processes

	It seems like 2 is the most flexible and most suited to IrisProcess. How
	to implement it?
	  - customise IrisThread and run it as IrisProcessThread? In which case
	    each IrisProcess would act like a subclass of IrisScheduler.
	  - create IrisProcessScheduler which handles all processes, but still runs
	    each one in its own IrisProcessThread. I like this option better because
	    the scheduler can then distribute threads etc. But this becomes just a
	    needless deputy of IrisSchedulerManager.
	  - IrisSchedulerManager could be extended to sensibly manage IrisProcessScheduler
	    and IrisScheduler together. The former is expected to be running
	    full-throttle, although the scheduler needs to know if it is waiting on
	    CPU time (in which case threads > cores is pointless) or IO (in which
	    case more threads = better, to a point). Either the user could tell it,
	    or it could experiment by adding one extra thread and seeing if work
	    goes 2x as fast or the same speed. A sort of
	    iris_task_set_performance_hint() taking IRIS_CPU_BOUND or IRIS_IO_BOUND
	    ... would this be useful for tasks as well? Yes, it makes no sense
	    scheduling a CPU bound task when one is already running ... I think
	    tasks and processes should run in together in the special scheduler,
	    so that (a) main one can be free for message delivery, and (b) we can
	    do 'joined-up thinking' like this ... or move that control to the
	    scheduler manager??? I don't know :(

	A quick fix might be to allow setting a process on a thread, so it can
	work out what to do a bit better .. 

	Should we use IrisWSScheduler? I guess it can't hurt, although it shouldn't
	be too much of an improvement just because process threads should mostly
	have their own work to do. Not a priority.

	Is it possible to maintain IrisProcess as a subclass of IrisTask in all
	this ?

	Also, I don't think there is any need to use a coordination arbiter on the
	process work ports, the messages can be processed in O(1) time. In fact, we
    could perhaps use iris_arbiter_coordinate() properly, so that control
    messages (cancel, etc.) go on the exclusive receiver and block work items
    until the message is processed. Status messages of course are sent & not
    received so they would be unaffected.

Progress widgets

	The progress monitor widgets should make sure that they do not expand to
	comical sizes, groups should be collapsed and scroll bars added etc.

	The 'plural' parameter, which currently does nothing, is intended to merge
	similar groups to save space, eg. importing 6 directories could each have
	the plural "Importing files" so on their own they display as "Importing
	/home/foo/bar" but when space becomes short they are collapsed to "Importing
	files" rather than showing 6 collapsed processes/groups. Remember to update
	all the docs in iris-progress-monitor.c when you implement this!

	It would be faster to only update progress monitor labels/title bars
	when the string has changed; only relevent with %-ages and even then
	probably not a massive improvement

	A useful addition might be a simple IrisProgressBar, which would watch a process,
	group, task etc. and could just be embedded in an app's status bar or main window.

	One thing we could do is give progress watches a textual status. So it
	starts as "Preparing ..." and then goes NULL so the "1 item of 166" comes
	in to play. But (and this stuff is most useful in activity mode) it can
	also set the text to anything it wants. What about none? Maybe have
	IRIS_PROGRESS_NO_TEXT display style? Would it make sense to give processes
	and even tasks a way to set their status, or do it on the watch? Definitely
	put the API in process and tasks, there could be more consumers than just
	watchers ...  ... I like this idea.

	We could also add custom display text, eg. "%i sheep of %i". Could that be
	done through status text? Maybe not the best way ..

	When totals are totally estimated, maybe "1 item of about 500" would make
	more sense ... allow somehow setting 'inaccurate' flag in
	iris_progress_set_output_estimation(), which would add "about" and maybe
	round the figure off to the nearest ten/hundred.

	The group progress bar in activity mode gets a bit weird. Best demonstrated
	in examples/progress-chains if you start loads of chains up; the progress
	bar might get a pulse step too low to actually go anywhere, or it's
	accounting for getting updates from 10 processes at once but actually only
	3 are running and sending updates. It all needs a bit more work, but this
	is not exactly vital code :)

Tests

	Would it make sense to run task and process tests with every scheduler,
	including the mock? Or at least mock, standard and gmain.

Alex added warnings for GSimpleAsyncResult when not used from main thread.
We need to implement our own now since this isn't reusable.

How does Iris relate to GThreadPool? Have we reinvented things we could
actually pull in from GLib?

Introspection. See:
  http://live.gnome.org/GObjectIntrospection/WritingBindingableAPIs

There are other FIXME's lurking in the code no doubt :)

---------------------------------------------------------------------------
Optimization TODO's
---------------------------------------------------------------------------

iris_message_unref()

	This method shows up on the profile. It has considerable wait time
	which is probably attributed to using g_slice_*(). We should look
	at options from pulse audio which use lock-free algorithms.

	The changes here should also be applied to the IrisThreadWork
	data structure.

	Lets verify this is really an issue, I highly doubt it now.  The
	frequent allocations for thread work might be a good idea to move
	to a free list though, so we reduce pressure on gslice.

iris_port_post()
iris_receiver_deliver_real()

	These related methods have significant wait time. This could be
	both from the atomic operations as well as the locks incurred.
	How can we reduce the potential for lock in these situations?

In iris-progress-monitor.c I recommend keeping an IrisProgressMonitor object
around but hidden throughout the running of the program rather than creating
and then destroying one again. Is this actually the best way? I imagine that
it is, that was why I recommended it.

Remove tests that aren't any use any more

Other superfluous stuff:
  * IrisProgressMonitor->remove_watch() doesn't need to be part of the
    interface

---------------------------------------------------------------------------
Niceties
---------------------------------------------------------------------------

I'm not sure about the name iris_process_no_more_work(). How about something
like iris_process_preparation_complete()? You can then explain the
cancel-doesn't-take-effect-until-no-more-work thing in terms of a "preparation
phase" which keeps the task alive. Although don't confuse it with preparation
in terms of connecting processes, adding task deps etc. Maybe that stuff can
just be called the creation phase.

IrisProcess source/sink notifications could use the IrisTask observer mechanism,
without treating the processes as actual dependencies. I guess you need to
distinguish the two; blocking dependencies (for tasks) and chaining dependencies
(for process).

IrisMessage could actually become a thin wrapper around a GVariant "(d*)"

Would it be a good idea to prevent progress bars from going backwards? ie.
if the fraction drops, just wait until it gets back to where it was rather
than showing a regression.

Stress the point that all of libiris is MT-safe and all of libiris-gtk is not

Processes should be throttleable - for example, say we are indexing the entire
file system. A directory crawler process searches the FS for files recursively,
but it may as well read the first 100 files, count the number of files in
subdirectories not yet touched (to give the user better info) and then wait for
the next processes to start working.

Make branches of some GNOME apps to use Iris!
For example: Nautilus, .. who else uses progress bars so much?

This is a GTK+ theme bug, but the 'expander in an infobar' is pretty ugly on hover
at least with clearlooks. One theme has progress bars in an infobar with a grey
background behind their rounded corners as well.

In the tests and examples, a lot of tasks are never unreferenced. This isn't
setting a good example!!

The cancel button is actually in quite an ugly place in GtkIrisProgressDialog.
This is the best Gtk+ can do without some special case code. The ideal design
is for the cancel button to line up centre-to-centre with the progress bar (in
single watch cases) or the group title, but without causing any of the padding
to change when the button is bigger than the widget it's in line with (which is
normally the case). This leads to unevenly-padded dialogs that look even worse.
The solution would be to put the buttons in a separate GtkFixed to the right of
the progress widgets, and on size-allocated for the dialog or add/removal of
widgets, the buttons are lined up with these widgets manually in a signal
handler. (If for some reason the font size was miniature this might cause the
buttons not to fit (b/c their icon size is fixed). This could be handled with
some sort of size-request hack but is probably too rare a case to worry about.)

---------------------------------------------------------------------------
The Future
---------------------------------------------------------------------------

If this project ever gets more adoption:
	http://ssickert.wordpress.com/2010/11/22/taskview-release/
it might be worth creating an IrisProgressMonitor that could send task status
over dbus according to the spec.

It's also worth looking at how Nautilus does things. A few differences are:
  - a progress dialog can be closed, and it will then become a resident
    notification or status icon and will stay that way if further watches are
    added. This something it would be quite easy to implement outside of Iris,
    so whether it should be added depends on if there are other uses/if it's
    generally considered a good design feature.
  - rather than a custom object for the overall progress monitor, there are
    NautilusProgressInfoWidget and NautilusProgressUIManager classes ... it's
    hard to see which is the better design, but I think the only real advantage
    of the Nautilus way is it's easier to alter the way the dialog works while
    still using the widget display code. I'm not sure why you would want to do
    that though unless you were making a change big enough that you'd probably
    want to display the watch in a different way anyway ..
  - ProgressInfo (our equivalent of progresswatches I think) have a
    GCancellable. IrisTask takes a totally different approach to cancelling, I
    don't know enough about GCancellable to see which makes more sense ...
  - ProgressInfo has a started signals, these could go on IrisTask if
    necessary


It would be cool to animate watches disappearing from the progress dialog. This
is pie in the sky :)
