* Fix waf for nested project ...

---------------------------------------------------------------------------
Iris 0.3.0
---------------------------------------------------------------------------

* Fix iris_receiver_abort(), so tests pass more :) Especially: 
    receiver-scheduler/*/destruction/

* Rewrite iris_port_flush(), to fix the race condition there.
  Race is currently triggered in:
    receiver-scheduler/default/live 2
    process-1/recurse
    progress-dialog-gtk-1/recurse
  where iris_receiver_resume() gets called but somehow iris_port_flush() races
  with a call to iris_port_post() from another thread and the result is that
  execution of the queue freezes up.

* Separate libiris from gtk, ie. create a libiris-gtk
  --> stress the point that all of libiris is MT-safe and all of libiris-gtk is not
  --> also don't forget you need gtk+-2.18 or better for gtkinfobar

* Prevent arbiters from being connected to receivers that have already processed
  messages.

* Cancel button, reimplement this! Make it work in progress-tasks too!!
  Remember to doc. in iris-progress-monitor.c

* fix watch_chain using gtk_box_reorder_child

* Fix progress-tasks, current bugs include:
   - progress-tasks actually sometimes misses tasks or does 2 at once
   - the type of progress monitor should change as soon as the toggle box changes :)
   - cancelling does not work (probably not implemented :)
  -> remember to write unit tests for any bugs identified!!

* Since STATUS_COMPLETE is sent when the task receives 'finish', why not rename it to 'finish'
  also???

* How much of tests/progress-monitor-gtk-1 could use wait-func instead of count-sheep-func???

* Note in docs that irisprocess will not send any progress messages until it is running,
  and that probably won't change (too difficult)

* Tests should always use a fresh scheduler, no?

* Bump version to 0.3, and maybe give Iris a blog post :)

---------------------------------------------------------------------------
Missing or Incompleteness
---------------------------------------------------------------------------

waf should build the gtk-docs

The IrisProgressMonitor examples could perhaps be described using a couple of
screenshots.
To do this in gtk-doc you do:
  <inlinegraphic fileref="gnome-foo.png" format="PNG" />
then add the file in doc/makefile.am:
  HTML_IMAGES= \
          $(srcdir)/images/gnome-foo.png

When I added the 'closed' API I broke IrisLFQueue and IrisWSQueue :( While
there, they each have their own unit tests which duplicate some code, we
could make a shared test.

We are not currently destroying threads ever. After they are created they
stay created until the end of the process. We need to find a way to
periodically walk the free-list to shutdown old threads.

IrisScheduler

	Either add use of execution notify, or remove it from the
	signatures.

	iris_scheduler_foreach () is a big bunch of code that should be a lot
	neater.

	Scheduler finalization: doesn't really work at the moment. We need:
	  - it not to destroy itself until all of its work queues are done,
	    *or* it to give up its work queues ..


IrisMessage

	We should make the ref-counting for messages use the sink concept
	so that you don't need to unref your messages if you hit the usual
	use-case of create->post.

IrisProcess

	Currently IrisProcess is really, really dumb and inefficient (especially when
	idle). The current system is to see if there is any work using try_pop() and if
	not, re-enqueue the process back into the scheduler to check again immediately.
	This is good for now because the scheduler does not get as blocked up but is
	very wasteful when processes are waiting around.

	Things to consider:
	  - we could create an IrisProcessScheduler, which could peek into queues
	    and not execute a work function for processes with no work, saving on
	    having a thread blocking on the queue.  This falls down on the fact
	    that only Windows can block on multiple conds at once in one thread, I
	    think. Unless we create a special queue where they all signal one cond
	    to wake up the scheduler's main thread, this might be a no go

	  - is one thread per process a reasonable assumption? if the process runs
	    IO-bound non-interdependent items, it really wants as many threads as
	    are available within reason, and certainly sharing threads would not
	    make sense. For CPU bound processes there is no reason to run more
	    threads than there are cores, but a dedicated thread is still good
	    perhaps to improve multitasking. The only time a process
	    would not need its own dedicated thread is if it spends most of it's
	    time waiting for work, but is that a valid use-case? The whole point
	    of process is that it's stuff that takes a long time to process, if
	    we have more occasional single-shot work then IrisTask is a better fit.
	
	So the possible models:
	  1. no dedicated threads, work items pulled from the process and scheduled
	     by IrisProcessScheduler => silly for IO-bound processes
	  2. one dedicated thread which passes work off into others when need be
	     (exactly how IrisThread works in fact - can we not take advantage of
	     that?) => good for CPU and IO-bound processes
	  3. multiple dedicated threads all running through the work queue
	     => good for IO bound processes

	It seems like 2 is the most flexible and most suited to IrisProcess. How
	to implement it?
	  - customise IrisThread and run it as IrisProcessThread? In which case
	    each IrisProcess would act like a subclass of IrisScheduler.
	  - create IrisProcessScheduler which handles all processes, but still runs
	    each one in its own IrisProcessThread. I like this option better because
	    the scheduler can then distribute threads etc. But this becomes just a
	    needless deputy of IrisSchedulerManager.
	  - IrisSchedulerManager could be extended to sensibly manage IrisProcessScheduler
	    and IrisScheduler together. The former is expected to be running
	    full-throttle, although the scheduler needs to know if it is waiting on
	    CPU time (in which case threads > cores is pointless) or IO (in which
	    case more threads = better, to a point). Either the user could tell it,
	    or it could experiment by adding one extra thread and seeing if work
	    goes 2x as fast or the same speed.

	Should we use IrisWSScheduler? I guess it can't hurt, although it shouldn't
	be too much of an improvement just because process threads should mostly
	have their own work to do. Not a priority.

	Is it possible to maintain IrisProcess as a subclass of IrisTask in all
	this ?

	Also, I don't think there is any need to use a coordination arbiter on the
	process work ports, the messages can be processed in O(1) time. In fact, we
    could perhaps use iris_arbiter_coordinate() properly, so that control
    messages (cancel, etc.) go on the exclusive receiver and block work items
    until the message is processed. Status messages of course are sent & not
    received so they would be unaffected.

Progress widgets

	The progress monitor widgets should make sure that they do not expand to
	comical sizes, groups should be collapsed and scroll bars added etc.

	The 'plural' parameter, which currently does nothing, is intended to merge
	similar groups to save space, eg. importing 6 directories could each have
	the plural "Importing files" so on their own they display as "Importing
	/home/foo/bar" but when space becomes short they are collapsed to "Importing
	files" rather than showing 6 collapsed processes/groups. Remember to update
	all the docs in iris-progress-monitor.c when you implement this!

	It would be faster to only update progress monitor labels/title bars
	when the string has changed; only relevent with %-ages and even then
	probably not a massive improvement

	A useful addition might be a simple IrisProgressBar, which would watch a process,
	group, task etc. and could just be embedded in an app's status bar or main window.

Alex added warnings for GSimpleAsyncResult when not used from main thread.
We need to implement our own now since this isn't reusable.

Should anything be allowed to happen after execution begins? Currently on tasks
you can add callbacks/errbacks and dependencies, add watches, and it even seems
you can execute tasks again once they are finished :/ This is a reciple for
nasty race conditions down the line. It should be handled but not allowed, using
an assertion or two. For processes you should be allowed to do stuff until BOTH
iris_process_no_more_work() or iris_process_run() are called, for tasks just
until iris_tasks_run() is called. Need to update:
  -> the docs
  -> put in the tests and the assertions

What about chaining together processes that are being cancelled, is this possible?
The tests could be cancelled before they run; add a testcase for this.

Finalisation: a few issues here.
  * make sure nothing can be finalized while it still has messages to process.

  * The best way forward for destruction is to make IrisTask hold a reference to
    itself, released when execution is complete. The user can keep it alive as
    long as they hold a reference, but it will never be destroyed until it
    is cancelled or it completes.

  * All this needs thorough testing of course!

There are other FIXME's lurking in the code no doubt :)

---------------------------------------------------------------------------
Optimization TODO's
---------------------------------------------------------------------------

iris_message_unref()

	This method shows up on the profile. It has considerable wait time
	which is probably attributed to using g_slice_*(). We should look
	at options from pulse audio which use lock-free algorithms.

	The changes here should also be applied to the IrisThreadWork
	data structure.

	Lets verify this is really an issue, I highly doubt it now.  The
	frequent allocations for thread work might be a good idea to move
	to a free list though, so we reduce pressure on gslice.

iris_port_post()
iris_receiver_deliver_real()

	These related methods have significant wait time. This could be
	both from the atomic operations as well as the locks incurred.
	How can we reduce the potential for lock in these situations?

Valgrind everything to check for leaks

In iris-progress-monitor.c I recommend keeping an IrisProgressMonitor object
around but hidden throughout the running of the program rather than creating
and then destroying one again. Is this actually the best way? I imagine that
it is, that was why I recommended it.

---------------------------------------------------------------------------
Niceties
---------------------------------------------------------------------------

Processes should 'feed forward' the totals when hooked up - makes no
sense for B to have its total as A's processed count. It's normally the
case that when A and B are connected, B has A->total_items left to process
as well ... but this is not necessarily true. The solution must be to add an
item_enqueued() class member, which by default calls
iris_process_notify_future_work_item (B) .. but can be overridden by
subclassing. Or maybe it should be a signal so the user does not need to
subclass.

Processes should be throttleable - for example, say we are indexing the entire
file system. A directory crawler process searches the FS for files recursively,
but it may as well read the first 100 files, count the number of files in
subdirectories not yet touched (to give the user better info) and then wait for
the next processes to start working.

Make branches of some GNOME apps to use Iris!
For example: Nautilus, .. who else uses progress bars so much?

This is a GTK+ theme bug, but the 'expander in an infobar' is pretty ugly on hover
at least with clearlooks. One theme has progress bars in an infobar with a grey
background behind their rounded corners as well.

In the tests and examples, a lot of tasks are never unreferenced. This isn't
setting a good example!!

---------------------------------------------------------------------------
The Future
---------------------------------------------------------------------------

If this project ever gets more adoption:
	http://ssickert.wordpress.com/2010/11/22/taskview-release/
it might be worth creating an IrisProgressMonitor that could send task status
over dbus according to the spec.

It would be cool to animate watches disappearing from the progress dialog. This
is pie in the sky :)
